{
  "cells": [
    {
      "cell_type": "code",
      "id": "ohbwds2smll",
      "source": [
        "# ===========================================\n",
        "# GOOGLE COLAB SETUP\n",
        "# ===========================================\n",
        "# Run this cell FIRST if using Google Colab\n",
        "\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Install dependencies\n",
        "    !pip install -q aisuite openai duckdb pandas pydantic python-dotenv tavily-python wikipedia markdown\n",
        "\n",
        "    # Clone the repo and navigate to workshop folder\n",
        "    !git clone -b dev https://github.com/nestauk/discovery_residency_agentic_ai.git\n",
        "    %cd discovery_residency_agentic_ai/discovery_residency_agentic_ai/evals_deep_dive\n",
        "\n",
        "    # Set up API keys from Colab Secrets\n",
        "    from google.colab import userdata\n",
        "    import os\n",
        "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "    os.environ['TAVILY_API_KEY'] = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "    print(\"âœ… Colab setup complete! API keys loaded from Secrets.\")\n",
        "else:\n",
        "    print(\"Not running in Colab - skipping setup.\")"
      ],
      "metadata": {
        "id": "ohbwds2smll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "intro-header",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "intro-header"
      },
      "source": [
        "# Evaluating AI Agents\n",
        "## A Hands-On Workshop\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nestauk/discovery_residency_agentic_ai/blob/dev/discovery_residency_agentic_ai/evals_deep_dive/workshop.ipynb)\n",
        "\n",
        "Welcome! In this workshop, you'll learn how to design evaluations for AI agents."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe8a4c50-10da-4441-9d2c-c99206e843fa",
      "metadata": {
        "id": "fe8a4c50-10da-4441-9d2c-c99206e843fa"
      },
      "source": [
        "![Agent Loop](https://github.com/nestauk/discovery_residency_agentic_ai/blob/dev/discovery_residency_agentic_ai/evals_deep_dive/assets/anthropic-agent-loop.webp?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pt95cs5vta",
      "metadata": {
        "id": "pt95cs5vta"
      },
      "source": [
        "## Two \"Axes\" of Evaluation\n",
        "\n",
        "When evaluating AI agents, we think along **two axes**:\n",
        "\n",
        "*Inspired by [Andrew Ng's Agentic AI course](https://www.deeplearning.ai/short-courses/)*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n41fu0dk4k",
      "metadata": {
        "id": "n41fu0dk4k"
      },
      "source": [
        "### Axis 1: Per example ground truth?\n",
        "\n",
        "- **Per example ground truth**: You know the correct answer for each test case\n",
        "  - *Example: \"Extract the date from this invoice\" â†’ expected: \"2024-03-15\"*\n",
        "- **No per example ground truth**: There's no single \"correct\" answer\n",
        "  - *Example: \"Write marketing copy for this product\"*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "emt8xb3ga9t",
      "metadata": {
        "id": "emt8xb3ga9t"
      },
      "source": [
        "### Axis 2: Evaluate with code or LLM-as-judge?\n",
        "\n",
        "- **Evaluate with code (objective)**: Code can verify correctness\n",
        "  - *Example: `if extracted_date == actual_date: num_correct += 1`*\n",
        "- **LLM-as-judge (subjective)**: Requires an LLM to evaluate quality\n",
        "  - *Example: \"Grade this chart according to whether it has clear axes labels...\"*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2lg5aoag35e",
      "metadata": {
        "id": "2lg5aoag35e"
      },
      "source": [
        "### The Evaluation Quadrant\n",
        "\n",
        "These two axes give us four quadrants â€” each with different evaluation strategies:\n",
        "\n",
        "![Two Axes of Evaluation](https://github.com/nestauk/discovery_residency_agentic_ai/blob/dev/discovery_residency_agentic_ai/evals_deep_dive/assets/two-axes-of-evaluation.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed7roj6kg2",
      "metadata": {
        "id": "ed7roj6kg2"
      },
      "source": [
        "### Today's Focus\n",
        "\n",
        "We'll explore **two quadrants** with hands-on examples:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uckxdjgc0q",
      "metadata": {
        "id": "uckxdjgc0q"
      },
      "source": [
        "**Top-left: SQL Agent**\n",
        "- Has ground truth (we know the correct query results)\n",
        "- Evaluate with code (compare actual vs expected)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n1cssfdviyn",
      "metadata": {
        "id": "n1cssfdviyn"
      },
      "source": [
        "**Bottom-right: Web Search Agent**\n",
        "- No ground truth (no single \"correct\" research summary)\n",
        "- LLM-as-judge (use a rubric to assess quality)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup-header",
      "metadata": {
        "id": "setup-header"
      },
      "source": [
        "---\n",
        "## Setup\n",
        "\n",
        "Run this cell to import everything we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup-code",
      "metadata": {
        "id": "setup-code",
        "outputId": "340af819-4058-4039-d419-f7846c1eed7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Environment\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from datetime import datetime\n",
        "from aisuite import Client\n",
        "\n",
        "# Utilities\n",
        "from utils.helpers import make_verbose_tool\n",
        "from utils.display import print_html, display_rubric_scores, display_test_results\n",
        "from utils.evaluators import evaluate_sql_result, llm_judge\n",
        "\n",
        "# Import the tool FUNCTION (aisuite calls this automatically)\n",
        "from tools.research_tools import tavily_search_tool\n",
        "\n",
        "# Initialize the LLM client\n",
        "client = Client()\n",
        "\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xzxil4cwhij",
      "metadata": {
        "id": "xzxil4cwhij"
      },
      "source": [
        "### API Key Configuration\n",
        "\n",
        "This workshop uses two external services:\n",
        "\n",
        "| Service | Purpose | How to Get |\n",
        "|---------|---------|------------|\n",
        "| **Tavily** | Web search tool | Free at [tavily.com](https://tavily.com) |\n",
        "| **OpenAI** | LLM for agents | [platform.openai.com](https://platform.openai.com/api-keys) |\n",
        "\n",
        "**Local setup**: Create a `.env` file with your keys.\n",
        "\n",
        "**Google Colab**: Use Colab Secrets (click the key icon in the left sidebar) to add:\n",
        "- `OPENAI_API_KEY`\n",
        "- `TAVILY_API_KEY`\n",
        "\n",
        "Run the cell below to check your keys are configured:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dhlbom0e9vr",
      "metadata": {
        "id": "dhlbom0e9vr",
        "outputId": "d37c1617-1d95-4eeb-dda0-b6f65f5b1d82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… TAVILY_API_KEY found\n",
            "âœ… OPENAI_API_KEY found â†’ using openai:gpt-5-mini\n",
            "\n",
            "âœ… All API keys configured! You're ready to go.\n"
          ]
        }
      ],
      "source": [
        "# Check API keys and detect which LLM provider to use\n",
        "from utils.helpers import check_api_keys\n",
        "MODEL = check_api_keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71274brhrhn",
      "metadata": {
        "id": "71274brhrhn"
      },
      "source": [
        "---\n",
        "## SQL Agent â€” Objective Evaluation\n",
        "\n",
        "Let's start with the simplest type of evaluation: **objective with ground truth**.\n",
        "\n",
        "We have a SQL agent that answers questions about a product nutrition database.\n",
        "\n",
        "The evaluation is simple: **does the query return the expected result?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tvpf3qosgvl",
      "metadata": {
        "id": "tvpf3qosgvl"
      },
      "source": [
        "### The Database\n",
        "\n",
        "Our database contains nutrition information for food products:\n",
        "- `product_name` - Product name\n",
        "- `kcal_per_100g`, `protein_per_100g`, `sugar_per_100g`, etc.\n",
        "- `npm_score` - Nutrient Profile Model score (UK HFSS metric)\n",
        "- `converted_npm_score` - NPM score converted using Oxford method (npm_score*-2 + 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac943ain4z5",
      "metadata": {
        "id": "ac943ain4z5",
        "outputId": "9cdb9ac0-fcb2-4045-e577-dc453abcae60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Database ready! 25 products loaded.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_name</th>\n",
              "      <th>kcal_per_100g</th>\n",
              "      <th>protein_per_100g</th>\n",
              "      <th>sugar_per_100g</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Whole Milk</td>\n",
              "      <td>64.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Greek Yogurt</td>\n",
              "      <td>97.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cheddar Cheese</td>\n",
              "      <td>416.0</td>\n",
              "      <td>25.4</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>White Bread</td>\n",
              "      <td>265.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wholemeal Bread</td>\n",
              "      <td>247.0</td>\n",
              "      <td>10.9</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      product_name  kcal_per_100g  protein_per_100g  sugar_per_100g\n",
              "0       Whole Milk           64.0               3.4             4.7\n",
              "1     Greek Yogurt           97.0               9.0             3.6\n",
              "2   Cheddar Cheese          416.0              25.4             0.1\n",
              "3      White Bread          265.0               9.0             5.0\n",
              "4  Wholemeal Bread          247.0              10.9             4.2"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set up the products database\n",
        "from tools.sql_tools import db, setup_products_db\n",
        "\n",
        "count = setup_products_db()\n",
        "print(f\"Database ready! {count} products loaded.\")\n",
        "\n",
        "# Quick peek at the data\n",
        "db.execute(\"SELECT product_name, kcal_per_100g, protein_per_100g, sugar_per_100g FROM products LIMIT 5\").fetchdf()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rrl81sofiyl",
      "metadata": {
        "id": "rrl81sofiyl"
      },
      "source": [
        "### The Tool\n",
        "\n",
        "A **tool** is just a function that the LLM can call. Here's our SQL query tool:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cyt6r2vt1j7",
      "metadata": {
        "id": "cyt6r2vt1j7",
        "outputId": "5acbda44-046b-4503-b115-de91b5335dc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tool defined: sql_query_tool(query) -> list[dict]\n"
          ]
        }
      ],
      "source": [
        "# ===========================================\n",
        "# THE SQL QUERY TOOL\n",
        "# ===========================================\n",
        "# This is what the agent will use to execute SQL queries.\n",
        "# A tool is just a function that takes arguments and returns results.\n",
        "\n",
        "def sql_query_tool(query: str) -> list[dict]:\n",
        "    \"\"\"Execute a SQL query and return results as list of dicts.\"\"\"\n",
        "    try:\n",
        "        result = db.execute(query).fetchdf()\n",
        "        return result.to_dict(orient=\"records\")\n",
        "    except Exception as e:\n",
        "        return [{\"error\": str(e)}]\n",
        "\n",
        "print(\"Tool defined: sql_query_tool(query) -> list[dict]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "luxzqyv4c2n",
      "metadata": {
        "id": "luxzqyv4c2n"
      },
      "source": [
        "### Computing Ground Truth\n",
        "\n",
        "Before we can test the agent, we need to know the **correct answers**.\n",
        "\n",
        "Let's run SQL queries directly on the database to establish our ground truth values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cedf1bf",
      "metadata": {
        "id": "4cedf1bf",
        "outputId": "514aefc0-b521-49e7-df17-8218af7a2b30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'count': 9}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Q1: How many products are above the target converted NPM score threshold of 69?\n",
        "sql_query_tool(\"\"\"\n",
        "    SELECT COUNT(*) as count\n",
        "    FROM products\n",
        "    WHERE converted_npm_score > 69\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a066f786",
      "metadata": {
        "id": "a066f786",
        "outputId": "55818c97-cc31-403a-9906-912e098ee14e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'pct': 36.0}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Q2: What percentage of products are above the threshold?\n",
        "sql_query_tool(\"\"\"\n",
        "    SELECT ROUND(100.0 * COUNT(*) FILTER (WHERE converted_npm_score > 69) / COUNT(*), 1) as pct\n",
        "    FROM products\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89fb62ad",
      "metadata": {
        "id": "89fb62ad",
        "outputId": "b5b12433-8bfa-46c0-8676-3218a9764142"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'product_name': 'Porridge Oats', 'total_protein_g': 110.0}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Q3: Which product has the highest absolute protein content?\n",
        "sql_query_tool(\"\"\"\n",
        "    SELECT product_name, ROUND(protein_per_100g * grams / 100, 1) as total_protein_g\n",
        "    FROM products\n",
        "    ORDER BY total_protein_g DESC\n",
        "    LIMIT 1\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf35c00",
      "metadata": {
        "id": "2cf35c00",
        "outputId": "03ef82e9-576c-4a17-f4ec-38a491b195b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'avg_kcal': 281.0}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Q4: What is the average kcal_per_100g across all products?\n",
        "sql_query_tool(\"\"\"\n",
        "    SELECT ROUND(AVG(kcal_per_100g)) as avg_kcal\n",
        "    FROM products\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01aa5af9",
      "metadata": {
        "id": "01aa5af9",
        "outputId": "b3d6fc65-5aa6-4ced-97ba-4869eb825e0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'product_name': 'Cheddar Cheese',\n",
              "  'converted_npm_score': 34,\n",
              "  'protein_per_100g': 25.399999618530273}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Q5: HARDER - Which products are in the bottom 25% for healthiness but top 25% for protein?\n",
        "sql_query_tool(\"\"\"\n",
        "    WITH ranked AS (\n",
        "        SELECT product_name, converted_npm_score, protein_per_100g,\n",
        "            NTILE(4) OVER (ORDER BY converted_npm_score ASC) as health_quartile,\n",
        "            NTILE(4) OVER (ORDER BY protein_per_100g DESC) as protein_quartile\n",
        "        FROM products\n",
        "    )\n",
        "    SELECT product_name, converted_npm_score, protein_per_100g\n",
        "    FROM ranked\n",
        "    WHERE health_quartile = 1 AND protein_quartile = 1\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rdgxkxutpj",
      "metadata": {
        "id": "rdgxkxutpj",
        "outputId": "8634fb60-adfe-47b7-ee60-438447c0ee29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SQL agent defined!\n"
          ]
        }
      ],
      "source": [
        "# ===========================================\n",
        "# THE SQL AGENT\n",
        "# ===========================================\n",
        "\n",
        "def sql_agent(question: str, model: str = MODEL) -> dict:\n",
        "    \"\"\"\n",
        "    Answer questions about the products database using SQL.\n",
        "\n",
        "    Returns:\n",
        "        dict with 'answer' (extracted value) and 'raw_response' (full LLM output)\n",
        "    \"\"\"\n",
        "    print(f\"Question: {question}\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You have access to a SQL database with a 'products' table containing food nutrition data.\n",
        "\n",
        "    Columns: product_name, grams, standardised_volume, kcal_per_100g, fat_per_100g,\n",
        "    satfat_per_100g, protein_per_100g, carbs_per_100g, sugar_per_100g,\n",
        "    sodium_per_100g, salt_per_100g, fibre_per_100g, npm_score, converted_npm_score\n",
        "\n",
        "    Answer this question: {question}\n",
        "\n",
        "    Instructions:\n",
        "    1. Write a SQL query to get the answer\n",
        "    2. Execute it using sql_query_tool\n",
        "    3. Return ONLY the final answer (a number, name, or short phrase)\n",
        "    \"\"\".strip()\n",
        "\n",
        "    tools = [make_verbose_tool(sql_query_tool, \"database\")]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "        max_turns=3,\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content\n",
        "    print(f\"Answer: {answer}\")\n",
        "    return {\"answer\": answer, \"raw_response\": response}\n",
        "\n",
        "print(\"SQL agent defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uksof5yt9vp",
      "metadata": {
        "id": "uksof5yt9vp"
      },
      "source": [
        "### Try it yourself!\n",
        "\n",
        "Test the agent with your own questions about the products database:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1vyfthgu70g",
      "metadata": {
        "id": "1vyfthgu70g",
        "outputId": "3b49e5a5-ef14-47ff-ea52-74f08ac9a9b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Which product has the highest nutrient density across all measures?\n",
            "  [database] Calling tool...\n",
            "  [database] query: SELECT product_name, COALESCE(converted_npm_score, npm_score) AS score\n",
            "FROM products\n",
            "ORDER BY score DESC\n",
            "LIMIT 1;\n",
            "  [database] Returned 1 results\n",
            "Answer: Chicken Breast\n"
          ]
        }
      ],
      "source": [
        "NATURAL_LANGUAGE_QUERY = \"Which product has the highest nutrient density across all measures?\"\n",
        "\n",
        "result = sql_agent(NATURAL_LANGUAGE_QUERY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ahb777338i",
      "metadata": {
        "id": "6ahb777338i"
      },
      "source": [
        "### Testing the Agent\n",
        "\n",
        "Now that we have ground truth, let's see if the agent can figure out the correct SQL queries on its own.\n",
        "\n",
        "We'll give it the same questions in natural language and check if its answers match:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pkp4kloo11",
      "metadata": {
        "id": "pkp4kloo11",
        "outputId": "061dc6bd-4596-480f-fb52-17d758092ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defined 4 test cases\n"
          ]
        }
      ],
      "source": [
        "# ===========================================\n",
        "# EVALUATION TEST CASES\n",
        "# ===========================================\n",
        "# Each test case has a question and the expected answer\n",
        "\n",
        "TEST_CASES = [\n",
        "    {\n",
        "        \"question\": \"What pct of products are above the target converted npm score threshold of 69?\",\n",
        "        \"expected\": \"36\",\n",
        "        \"comparison\": \"contains\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Which product has the highest absolute protein content, and how much is it?\",\n",
        "        \"expected\": \"Porridge Oats\",\n",
        "        \"comparison\": \"contains\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the average kcal_per_100g across all products? Round to the nearest whole number.\",\n",
        "        \"expected\": \"281\",\n",
        "        \"comparison\": \"contains\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Which products are in the bottom 25% for healthiness but top 25% for protein content?\",\n",
        "        \"expected\": \"Cheddar Cheese\",\n",
        "        \"comparison\": \"contains\"\n",
        "    },\n",
        "]\n",
        "\n",
        "print(f\"Defined {len(TEST_CASES)} test cases\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q5k9fgzlbkr",
      "metadata": {
        "id": "q5k9fgzlbkr",
        "outputId": "300b48c7-f312-4f5e-9e07-ecc6cf337166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running all test cases...\n",
            "\n",
            "Question: What pct of products are above the target converted npm score threshold of 69?\n",
            "  [database] Calling tool...\n",
            "  [database] query: SELECT ROUND(100.0 * SUM(CASE WHEN converted_npm_score > 69 THEN 1 ELSE 0 END) / COUNT(*), 2) AS pct_above_69 FROM products;\n",
            "  [database] Returned 1 results\n",
            "Answer: 36.0%\n",
            "\n",
            "Question: Which product has the highest absolute protein content, and how much is it?\n",
            "  [database] Calling tool...\n",
            "  [database] query: SELECT product_name, (protein_per_100g * grams / 100.0) AS protein_grams\n",
            "FROM products\n",
            "ORDER BY protein_grams DESC\n",
            "LIMIT 1;\n",
            "  [database] Returned 1 results\n",
            "Answer: Porridge Oats â€” 110.0 g\n",
            "\n",
            "Question: What is the average kcal_per_100g across all products? Round to the nearest whole number.\n",
            "  [database] Calling tool...\n",
            "  [database] query: SELECT ROUND(AVG(kcal_per_100g)) AS avg_kcal FROM products;\n",
            "  [database] Returned 1 results\n",
            "Answer: 281\n",
            "\n",
            "Question: Which products are in the bottom 25% for healthiness but top 25% for protein content?\n",
            "  [database] Calling tool...\n",
            "  [database] query: WITH q AS (\n",
            "  SELECT product_name,\n",
            "         converted_npm_score,\n",
            "         protein_per_100g,\n",
            "         NTILE(4) OVER (ORDER BY converted_npm_score) AS health_quartile,\n",
            "         NTILE(4) OVER (ORDER BY protein_per_100g DESC) AS protein_quartile\n",
            "  FROM products\n",
            ")\n",
            "SELECT product_name\n",
            "FROM q\n",
            "WHERE health_quartile = 1 AND protein_quartile = 4;\n",
            "  [database] Returned 2 results\n",
            "Answer: Butter, Olive Oil\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    .pretty-card{\n",
              "      font-family: ui-sans-serif, system-ui;\n",
              "      border: 2px solid transparent;\n",
              "      border-radius: 14px;\n",
              "      padding: 14px 16px;\n",
              "      margin: 10px 0;\n",
              "      background: linear-gradient(#fff, #fff) padding-box,\n",
              "                  linear-gradient(135deg, #3b82f6, #9333ea) border-box;\n",
              "      color: #111;\n",
              "      box-shadow: 0 4px 12px rgba(0,0,0,.08);\n",
              "    }\n",
              "    .pretty-title{\n",
              "      font-weight:700;\n",
              "      margin-bottom:8px;\n",
              "      font-size:14px;\n",
              "      color:#111;\n",
              "    }\n",
              "    /* ðŸ”’ Solo afecta lo DENTRO de la tarjeta */\n",
              "    .pretty-card pre,\n",
              "    .pretty-card code {\n",
              "      background: #f3f4f6;\n",
              "      color: #111;\n",
              "      padding: 8px;\n",
              "      border-radius: 8px;\n",
              "      display: block;\n",
              "      overflow-x: auto;\n",
              "      font-size: 13px;\n",
              "      white-space: pre-wrap;\n",
              "    }\n",
              "    .pretty-card img { max-width: 100%; height: auto; border-radius: 8px; }\n",
              "    .pretty-card table.pretty-table {\n",
              "      border-collapse: collapse;\n",
              "      width: 100%;\n",
              "      font-size: 13px;\n",
              "      color: #111;\n",
              "    }\n",
              "    .pretty-card table.pretty-table th,\n",
              "    .pretty-card table.pretty-table td {\n",
              "      border: 1px solid #e5e7eb;\n",
              "      padding: 6px 8px;\n",
              "      text-align: left;\n",
              "    }\n",
              "    .pretty-card table.pretty-table th { background: #f9fafb; font-weight: 600; }\n",
              "    </style>\n",
              "    <div class=\"pretty-card\"><div class=\"pretty-title\">SQL Agent Evaluation <span style=\"float: right; color: #f59e0b; font-weight: 700;\">3/4 passed</span></div>\n",
              "    <table style=\"width: 100%; border-collapse: collapse; font-size: 13px;\">\n",
              "        <thead>\n",
              "            <tr style=\"background: #f3f4f6;\">\n",
              "                <th style=\"padding: 8px 10px; text-align: left; font-weight: 600; border-bottom: 2px solid #e5e7eb;\">Question</th>\n",
              "                <th style=\"padding: 8px 10px; text-align: left; font-weight: 600; border-bottom: 2px solid #e5e7eb;\">Expected</th>\n",
              "                <th style=\"padding: 8px 10px; text-align: left; font-weight: 600; border-bottom: 2px solid #e5e7eb;\">Result</th>\n",
              "            </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "            \n",
              "        <tr style=\"background: #f9fafb;\">\n",
              "            <td style=\"padding: 8px 10px; border-bottom: 1px solid #e5e7eb;\">What pct of products are above the target converted npm score threshold of 69?</td>\n",
              "            <td style=\"padding: 8px 10px; border-bottom: 1px solid #e5e7eb; font-family: monospace; font-size: 12px;\">36</td>\n",
              "            <td style=\"padding: 8px 10px; border-bottom: 1px solid #e5e7eb;\">\n",
              "                <span style=\"color: #22c55e; font-weight: 700; margin-right: 6px;\">âœ“</span>\n",
              "                <span style=\"font-family: monospace; font-size: 12px;\">36.0%</span>\n",
              "            </td>\n",
              "        </tr>\n",
              "        \n",
              "        <tr style=\"background: #ffffff;\">\n",
              "            <td style=\"padding: 8px 10px; border-bottom: 1px solid #e5e7eb;\">Which product has the highest absolute protein content, and how much is it?</td>\n",
              "            <td style=\"padding: 8px 10px; border-bottom: 1px solid #e5e7eb; font-family: monospace; font-size: 12px;\">Porridge Oats</td>\n",
              "            <td style=\"padding: 8px 10px; border-bottom: 1px solid #e5e7eb;\">\n",
              "                <span style=\"color: #22c55e; font-weight: 700; margin-right: 6px;\">âœ“</span>\n",
              "                <span style=\"font-family: monospace; font-size: 12px;\">Porridge Oats â€” 110.0 g</span>\n",
              "            </td>\n",
              "        </tr>\n",
              "        \n",
              "        <tr style=\"background: #f9fafb;\">\n",
              "            <td style=\"padding: 8px 10px; border-bottom: 1px solid #e5e7eb;\">What is the average kcal_per_100g across all products? Round to the nearest whole number.</td>\n",
              "            <td style=\"padding: 8px 10px; border-bottom: 1px solid #e5e7eb; font-family: monospace; font-size: 12px;\">281</td>\n",
              "            <td style=\"padding: 8px 10px; border-bottom: 1px solid #e5e7eb;\">\n",
              "                <span style=\"color: #22c55e; font-weight: 700; margin-right: 6px;\">âœ“</span>\n",
              "                <span style=\"font-family: monospace; font-size: 12px;\">281</span>\n",
              "            </td>\n",
              "        </tr>\n",
              "        \n",
              "        <tr style=\"background: #ffffff;\">\n",
              "            <td style=\"padding: 8px 10px; border-bottom: 1px solid #e5e7eb;\">Which products are in the bottom 25% for healthiness but top 25% for protein content?</td>\n",
              "            <td style=\"padding: 8px 10px; border-bottom: 1px solid #e5e7eb; font-family: monospace; font-size: 12px;\">Cheddar Cheese</td>\n",
              "            <td style=\"padding: 8px 10px; border-bottom: 1px solid #e5e7eb;\">\n",
              "                <span style=\"color: #ef4444; font-weight: 700; margin-right: 6px;\">âœ—</span>\n",
              "                <span style=\"font-family: monospace; font-size: 12px;\">Butter, Olive Oil</span>\n",
              "            </td>\n",
              "        </tr>\n",
              "        \n",
              "        </tbody>\n",
              "    </table>\n",
              "    </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Run all test cases\n",
        "print(\"Running all test cases...\\n\")\n",
        "\n",
        "results = []\n",
        "for test in TEST_CASES:\n",
        "    result = sql_agent(test[\"question\"])\n",
        "    passed, _ = evaluate_sql_result(\n",
        "        result[\"answer\"],\n",
        "        test[\"expected\"],\n",
        "        test[\"comparison\"]\n",
        "    )\n",
        "    results.append({\n",
        "        \"question\": test[\"question\"],\n",
        "        \"expected\": test[\"expected\"],\n",
        "        \"actual\": result[\"answer\"],\n",
        "        \"passed\": passed\n",
        "    })\n",
        "    print()\n",
        "\n",
        "# Display results\n",
        "display_test_results(results, title=\"SQL Agent Evaluation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dz1jdqqm67p",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "dz1jdqqm67p"
      },
      "source": [
        "---\n",
        "### Key Takeaway: SQL Agent Evaluation\n",
        "\n",
        "The SQL agent evaluation is **objective with ground truth**:\n",
        "- We know the correct answer\n",
        "- We can check it with code\n",
        "- No ambiguity about pass/fail\n",
        "\n",
        "**But what about subjective qualities?**\n",
        "\n",
        "For these, we'd need **LLM-as-judge** evaluation.\n",
        "\n",
        "Let's test that out by looking at a more complex agent where evaluation isn't so clear-cut..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "agent-header",
      "metadata": {
        "id": "agent-header"
      },
      "source": [
        "---\n",
        "## The Research Agent\n",
        "\n",
        "We have a research agent that searches the web for information on any topic."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfn53u0831g",
      "metadata": {
        "id": "dfn53u0831g"
      },
      "source": [
        "### How it works\n",
        "\n",
        "The agent uses an LLM to call a tool:\n",
        "- **tavily_tool** - general web search  \n",
        "\n",
        "**You could design your own tools and plug them in!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "md573pyr9hr",
      "metadata": {
        "id": "md573pyr9hr",
        "outputId": "64ab0514-6145-481a-b8fc-7bfa41ce9d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Research agent defined!\n"
          ]
        }
      ],
      "source": [
        "# ===========================================\n",
        "# THE RESEARCH AGENT\n",
        "# ===========================================\n",
        "# This function orchestrates an LLM with a web search tool to research any topic.\n",
        "# You could modify this to use different tools or prompts.\n",
        "\n",
        "def research_agent(topic: str, model: str = MODEL) -> str:\n",
        "    \"\"\"\n",
        "    Research a topic using web search.\n",
        "\n",
        "    Args:\n",
        "        topic: The topic to research\n",
        "        model: The LLM to use for orchestration\n",
        "\n",
        "    Returns:\n",
        "        Research results with sources and URLs\n",
        "    \"\"\"\n",
        "    print(f\"Researching: {topic}\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a research assistant. Use tavily_search_tool ONCE to search for information,\n",
        "    then immediately provide a summary based on what you found.\n",
        "\n",
        "    Topic to research: {topic}\n",
        "\n",
        "    Instructions:\n",
        "    1. Search once for the topic\n",
        "    2. Summarise the key findings (2-3 paragraphs)\n",
        "    3. List the source URLs at the end\n",
        "\n",
        "    Today's date is {datetime.now().strftime('%Y-%m-%d')}.\n",
        "    \"\"\".strip()\n",
        "\n",
        "    tools = [make_verbose_tool(tavily_search_tool, \"web\")]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "        max_turns=2,  # 1 search + 1 response\n",
        "    )\n",
        "\n",
        "    print(\"Done!\")\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "print(\"Research agent defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m1f3srg2c7",
      "metadata": {
        "id": "m1f3srg2c7"
      },
      "source": [
        "### Try it yourself\n",
        "\n",
        "Let's test our research agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "topic-config",
      "metadata": {
        "id": "topic-config",
        "outputId": "7be25dab-12f2-4912-d6a1-206fa2553bec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic: recent developments in heat pump policy in the UK\n"
          ]
        }
      ],
      "source": [
        "# ===========================================\n",
        "# CHANGE THIS to research your own topic\n",
        "# ===========================================\n",
        "TOPIC = \"recent developments in heat pump policy in the UK\"\n",
        "\n",
        "print(f\"Topic: {TOPIC}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run-agent",
      "metadata": {
        "id": "run-agent",
        "outputId": "bc3a329d-be17-403a-b042-8d72d8e9c207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Researching: recent developments in heat pump policy in the UK\n",
            "  [web] Calling tool...\n",
            "  [web] query: recent developments in heat pump policy in the UK 2024 2025 government policy incentives heat pump grants boiler upgrade scheme heat pump rollout 2025 November\n",
            "  [web] max_results: 5\n",
            "  [web] include_images: False\n",
            "  [web] Returned 5 results\n",
            "Done!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    .pretty-card{\n",
              "      font-family: ui-sans-serif, system-ui;\n",
              "      border: 2px solid transparent;\n",
              "      border-radius: 14px;\n",
              "      padding: 14px 16px;\n",
              "      margin: 10px 0;\n",
              "      background: linear-gradient(#fff, #fff) padding-box,\n",
              "                  linear-gradient(135deg, #3b82f6, #9333ea) border-box;\n",
              "      color: #111;\n",
              "      box-shadow: 0 4px 12px rgba(0,0,0,.08);\n",
              "    }\n",
              "    .pretty-title{\n",
              "      font-weight:700;\n",
              "      margin-bottom:8px;\n",
              "      font-size:14px;\n",
              "      color:#111;\n",
              "    }\n",
              "    /* ðŸ”’ Solo afecta lo DENTRO de la tarjeta */\n",
              "    .pretty-card pre,\n",
              "    .pretty-card code {\n",
              "      background: #f3f4f6;\n",
              "      color: #111;\n",
              "      padding: 8px;\n",
              "      border-radius: 8px;\n",
              "      display: block;\n",
              "      overflow-x: auto;\n",
              "      font-size: 13px;\n",
              "      white-space: pre-wrap;\n",
              "    }\n",
              "    .pretty-card img { max-width: 100%; height: auto; border-radius: 8px; }\n",
              "    .pretty-card table.pretty-table {\n",
              "      border-collapse: collapse;\n",
              "      width: 100%;\n",
              "      font-size: 13px;\n",
              "      color: #111;\n",
              "    }\n",
              "    .pretty-card table.pretty-table th,\n",
              "    .pretty-card table.pretty-table td {\n",
              "      border: 1px solid #e5e7eb;\n",
              "      padding: 6px 8px;\n",
              "      text-align: left;\n",
              "    }\n",
              "    .pretty-card table.pretty-table th { background: #f9fafb; font-weight: 600; }\n",
              "    </style>\n",
              "    <div class=\"pretty-card\"><div class=\"pretty-title\">Research Results: recent developments in heat pump policy in the UK</div><pre><code>Summary (key recent developments)\n",
              "\n",
              "UK policy and market support for heat pumps has stepped up sharply in 2024â€“2025. The Boiler Upgrade Scheme (BUS) â€” the principal UK government capital-grant programme for replacing fossil-fuel heating â€” continues to offer up to Â£7,500 per installation, and the government set a substantially increased BUS budget for 2025/26 (reported as Â£295 million). Public bodies report a marked rise in uptake: the Climate Change Committeeâ€™s 2025 progress report notes a large year-on-year increase (around mid-double-digits) in installations in 2024, and industry coverage shows record application levels to BUS in 2025 as demand surged.\n",
              "\n",
              "Policy tweaks and scope changes are also underway to broaden pathways to lowâ€‘carbon heating. Guidance and scheme pages (Energy Saving Trust / GOV.UK) indicate changes in eligible technologies and growing administrative focus on rolling out support at scale (including recent reports that BUS eligibility was extended to additional technologies such as air-to-air heat pumps and heat batteries). Ofgem continues to administer the scheme and publish scheme data and budget information, while independent monitoring (CCC) highlights continuing work needed to accelerate installations to meet net-zero goals.\n",
              "\n",
              "Source URLs\n",
              "- https://www.find-government-grants.service.gov.uk/grants/boiler-upgrade-scheme-1\n",
              "- https://www.ofgem.gov.uk/environmental-and-social-schemes/boiler-upgrade-scheme-bus\n",
              "- https://energysavingtrust.org.uk/grants-and-loans/boiler-upgrade-scheme/\n",
              "- https://www.theccc.org.uk/publication/progress-in-reducing-emissions-2025-report-to-parliament/\n",
              "- https://www.renewableenergyhub.co.uk/blog/2025-brings-record-applications-for-the-boiler-upgrade-scheme</code></pre></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Run the research agent (this may take 10-30 seconds)\n",
        "research_output = research_agent(TOPIC)\n",
        "\n",
        "print_html(research_output, title=f\"Research Results: {TOPIC}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "llm-judge-header",
      "metadata": {
        "id": "llm-judge-header"
      },
      "source": [
        "---\n",
        "## LLM-as-Judge Evaluation\n",
        "\n",
        "Some qualities are **subjective** and hard to check with code:\n",
        "- Is the writing clear and well-organised?\n",
        "- Are the sources relevant to the query?\n",
        "- Is the information comprehensive?\n",
        "\n",
        "**Solution**: Use another LLM as a \"judge\" to score the output against a rubric."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rsx129jpc6l",
      "metadata": {
        "id": "rsx129jpc6l"
      },
      "source": [
        "### The Judge Prompt\n",
        "\n",
        "This is the actual prompt sent to the judge LLM. You can modify it!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "umy3i5gytwg",
      "metadata": {
        "id": "umy3i5gytwg"
      },
      "source": [
        "### How it works\n",
        "\n",
        "1. Define a **rubric** with scoring dimensions\n",
        "2. Build a **prompt** that asks the LLM to score each dimension\n",
        "3. Parse the structured JSON response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ragc7xeoate",
      "metadata": {
        "id": "ragc7xeoate",
        "outputId": "0b2f5b90-2076-43a7-8cfd-944d4250fb7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Judge prompt template defined!\n"
          ]
        }
      ],
      "source": [
        "# ===========================================\n",
        "# THE JUDGE PROMPT\n",
        "# ===========================================\n",
        "# This is the prompt sent to the judge LLM. Feel free to modify it.\n",
        "# - Change the calibration line to see how scores change\n",
        "# - Add more specific instructions\n",
        "# - Change the scoring scale\n",
        "\n",
        "JUDGE_PROMPT_TEMPLATE = \"\"\"You are an evaluation judge. Score the following output on each dimension.\n",
        "\n",
        "## Output to Evaluate:\n",
        "{output}\n",
        "\n",
        "## Scoring Rubric (score each 1-5):\n",
        "{rubric_text}\n",
        "\n",
        "## Instructions:\n",
        "For each dimension, provide:\n",
        "1. A score from 1 (poor) to 5 (excellent)\n",
        "2. A brief explanation (1-2 sentences)\n",
        "\n",
        "Be critical. A score of 5 should be rare.\n",
        "\n",
        "Respond in JSON format:\n",
        "{{\n",
        "    \"scores\": {{{score_template}}},\n",
        "    \"explanations\": {{{explanation_template}}}\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "print(\"Judge prompt template defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0zb9rglr7fep",
      "metadata": {
        "id": "0zb9rglr7fep"
      },
      "source": [
        "### Activity: Design a Rubric\n",
        "\n",
        "A rubric defines what dimensions to evaluate. **This is a design choice** â€” there's no single \"right\" rubric!\n",
        "\n",
        "We'll start with one criterion, then you'll add two more based on what *you* think matters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rubric-config",
      "metadata": {
        "id": "rubric-config",
        "outputId": "6767e419-ee75-4769-f122-106ccb943981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rubric has 5 dimension(s)\n",
            "  - coherence: Does the summary flow logically? Are ideas connected with smooth transitions?\n",
            "  - clarity: Is the writing clear and easy to understand?\n",
            "  - relevance: Does it stay focused on the research question?\n",
            "  - conciseness: Is it appropriately brief without unnecessary filler?\n",
            "  - persuasiveness: Does the article convince the user of a point of view?\n"
          ]
        }
      ],
      "source": [
        "# ===========================================\n",
        "# ACTIVITY: Design your rubric\n",
        "# ===========================================\n",
        "# We've started with ONE criterion.\n",
        "# Ask yourself: \"If I were grading this summary, what would I look for?\"\n",
        "\n",
        "RUBRIC = {\n",
        "    \"coherence\": \"Does the summary flow logically? Are ideas connected with smooth transitions?\",\n",
        "    # ADD 2 MORE CRITERIA BELOW\n",
        "    # Examples to consider:\n",
        "       \"clarity\": \"Is the writing clear and easy to understand?\",\n",
        "    #   \"completeness\": \"Does it cover the key aspects of the topic?\",\n",
        "       \"relevance\": \"Does it stay focused on the research question?\",\n",
        "    #   \"accuracy\": \"Are claims supported by the sources cited?\",\n",
        "       \"conciseness\": \"Is it appropriately brief without unnecessary filler?\",\n",
        "    \"persuasiveness\":\"Does the article convince the user of a point of view?\",\n",
        "}\n",
        "\n",
        "print(f\"Rubric has {len(RUBRIC)} dimension(s)\")\n",
        "for dim, desc in RUBRIC.items():\n",
        "    print(f\"  - {dim}: {desc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "llm-judge-eval",
      "metadata": {
        "id": "llm-judge-eval",
        "outputId": "d7ce2817-f15f-4df0-ef14-48a873931907"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    .pretty-card{\n",
              "      font-family: ui-sans-serif, system-ui;\n",
              "      border: 2px solid transparent;\n",
              "      border-radius: 14px;\n",
              "      padding: 14px 16px;\n",
              "      margin: 10px 0;\n",
              "      background: linear-gradient(#fff, #fff) padding-box,\n",
              "                  linear-gradient(135deg, #3b82f6, #9333ea) border-box;\n",
              "      color: #111;\n",
              "      box-shadow: 0 4px 12px rgba(0,0,0,.08);\n",
              "    }\n",
              "    .pretty-title{\n",
              "      font-weight:700;\n",
              "      margin-bottom:8px;\n",
              "      font-size:14px;\n",
              "      color:#111;\n",
              "    }\n",
              "    /* ðŸ”’ Solo afecta lo DENTRO de la tarjeta */\n",
              "    .pretty-card pre,\n",
              "    .pretty-card code {\n",
              "      background: #f3f4f6;\n",
              "      color: #111;\n",
              "      padding: 8px;\n",
              "      border-radius: 8px;\n",
              "      display: block;\n",
              "      overflow-x: auto;\n",
              "      font-size: 13px;\n",
              "      white-space: pre-wrap;\n",
              "    }\n",
              "    .pretty-card img { max-width: 100%; height: auto; border-radius: 8px; }\n",
              "    .pretty-card table.pretty-table {\n",
              "      border-collapse: collapse;\n",
              "      width: 100%;\n",
              "      font-size: 13px;\n",
              "      color: #111;\n",
              "    }\n",
              "    .pretty-card table.pretty-table th,\n",
              "    .pretty-card table.pretty-table td {\n",
              "      border: 1px solid #e5e7eb;\n",
              "      padding: 6px 8px;\n",
              "      text-align: left;\n",
              "    }\n",
              "    .pretty-card table.pretty-table th { background: #f9fafb; font-weight: 600; }\n",
              "    </style>\n",
              "    <div class=\"pretty-card\"><div class=\"pretty-title\">LLM Judge Evaluation</div>\n",
              "        <div style=\"margin-bottom: 12px;\">\n",
              "            <div style=\"display: flex; justify-content: space-between; margin-bottom: 4px;\">\n",
              "                <span style=\"font-weight: 600; text-transform: capitalize;\">coherence</span>\n",
              "                <span style=\"font-weight: 700;\">4/5</span>\n",
              "            </div>\n",
              "            <div style=\"background: #e5e7eb; border-radius: 4px; height: 8px; overflow: hidden;\">\n",
              "                <div style=\"background: linear-gradient(90deg, #3b82f6, #9333ea); width: 80.0%; height: 100%;\"></div>\n",
              "            </div>\n",
              "            <div style=\"font-size: 12px; color: #6b7280; margin-top: 4px;\">The summary is logically orderedâ€”policy changes, uptake data, and administrative updates follow a clear sequenceâ€”but transitions between points are serviceable rather than smooth.</div>\n",
              "        </div>\n",
              "        \n",
              "        <div style=\"margin-bottom: 12px;\">\n",
              "            <div style=\"display: flex; justify-content: space-between; margin-bottom: 4px;\">\n",
              "                <span style=\"font-weight: 600; text-transform: capitalize;\">clarity</span>\n",
              "                <span style=\"font-weight: 700;\">4/5</span>\n",
              "            </div>\n",
              "            <div style=\"background: #e5e7eb; border-radius: 4px; height: 8px; overflow: hidden;\">\n",
              "                <div style=\"background: linear-gradient(90deg, #3b82f6, #9333ea); width: 80.0%; height: 100%;\"></div>\n",
              "            </div>\n",
              "            <div style=\"font-size: 12px; color: #6b7280; margin-top: 4px;\">Overall clear and readable, though terms like \"mid-double-digits\" are vague and one or two long sentences reduce immediacy.</div>\n",
              "        </div>\n",
              "        \n",
              "        <div style=\"margin-bottom: 12px;\">\n",
              "            <div style=\"display: flex; justify-content: space-between; margin-bottom: 4px;\">\n",
              "                <span style=\"font-weight: 600; text-transform: capitalize;\">relevance</span>\n",
              "                <span style=\"font-weight: 700;\">5/5</span>\n",
              "            </div>\n",
              "            <div style=\"background: #e5e7eb; border-radius: 4px; height: 8px; overflow: hidden;\">\n",
              "                <div style=\"background: linear-gradient(90deg, #3b82f6, #9333ea); width: 100.0%; height: 100%;\"></div>\n",
              "            </div>\n",
              "            <div style=\"font-size: 12px; color: #6b7280; margin-top: 4px;\">Stays tightly focused on recent UK developments around heat-pump policy and the Boiler Upgrade Scheme, matching the stated purpose.</div>\n",
              "        </div>\n",
              "        \n",
              "        <div style=\"margin-bottom: 12px;\">\n",
              "            <div style=\"display: flex; justify-content: space-between; margin-bottom: 4px;\">\n",
              "                <span style=\"font-weight: 600; text-transform: capitalize;\">conciseness</span>\n",
              "                <span style=\"font-weight: 700;\">4/5</span>\n",
              "            </div>\n",
              "            <div style=\"background: #e5e7eb; border-radius: 4px; height: 8px; overflow: hidden;\">\n",
              "                <div style=\"background: linear-gradient(90deg, #3b82f6, #9333ea); width: 80.0%; height: 100%;\"></div>\n",
              "            </div>\n",
              "            <div style=\"font-size: 12px; color: #6b7280; margin-top: 4px;\">Concise and targeted with minimal filler, but a couple of sentences could be tightened or split for greater economy.</div>\n",
              "        </div>\n",
              "        \n",
              "        <div style=\"margin-bottom: 12px;\">\n",
              "            <div style=\"display: flex; justify-content: space-between; margin-bottom: 4px;\">\n",
              "                <span style=\"font-weight: 600; text-transform: capitalize;\">persuasiveness</span>\n",
              "                <span style=\"font-weight: 700;\">3/5</span>\n",
              "            </div>\n",
              "            <div style=\"background: #e5e7eb; border-radius: 4px; height: 8px; overflow: hidden;\">\n",
              "                <div style=\"background: linear-gradient(90deg, #3b82f6, #9333ea); width: 60.0%; height: 100%;\"></div>\n",
              "            </div>\n",
              "            <div style=\"font-size: 12px; color: #6b7280; margin-top: 4px;\">Informative and evidence-oriented but largely neutral; it reports developments without stronger evaluative claims or detailed supporting figures that would increase persuasive impact.</div>\n",
              "        </div>\n",
              "        \n",
              "    <div style=\"margin-top: 16px; padding-top: 12px; border-top: 1px solid #e5e7eb;\">\n",
              "        <div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
              "            <span style=\"font-weight: 700; font-size: 16px;\">Overall Score</span>\n",
              "            <span style=\"font-weight: 700; font-size: 20px; color: #3b82f6;\">4.0/5</span>\n",
              "        </div>\n",
              "    </div>\n",
              "    </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Build the prompt from template + rubric + output\n",
        "rubric_text = \"\\n\".join(f\"- **{dim}**: {desc}\" for dim, desc in RUBRIC.items())\n",
        "score_template = \", \".join(f'\"{dim}\": <score>' for dim in RUBRIC.keys())\n",
        "explanation_template = \", \".join(f'\"{dim}\": \"<explanation>\"' for dim in RUBRIC.keys())\n",
        "\n",
        "judge_prompt = JUDGE_PROMPT_TEMPLATE.format(\n",
        "    output=research_output,\n",
        "    rubric_text=rubric_text,\n",
        "    score_template=score_template,\n",
        "    explanation_template=explanation_template\n",
        ")\n",
        "\n",
        "# Run the LLM judge evaluation\n",
        "judge_result = llm_judge(judge_prompt, RUBRIC)\n",
        "\n",
        "# Display the results\n",
        "display_rubric_scores(judge_result, title=\"LLM Judge Evaluation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "human-review-header",
      "metadata": {
        "id": "human-review-header"
      },
      "source": [
        "---\n",
        "## Human Review Patterns\n",
        "\n",
        "Sometimes you need **human judgment** that can't be automated:\n",
        "- Is this factually accurate? (requires domain expertise)\n",
        "- Is this appropriate for our use case?\n",
        "- Would a user find this helpful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v9x9fw4i7jh",
      "metadata": {
        "id": "v9x9fw4i7jh"
      },
      "source": [
        "### When to use each method?\n",
        "\n",
        "| Method | Use When |\n",
        "|--------|----------|\n",
        "| **Automated** | Objective, code-checkable criteria |\n",
        "| **LLM-as-judge** | Subjective but definable in a rubric |\n",
        "| **Human review** | Domain expertise required, high stakes |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9085uknnhn",
      "metadata": {
        "id": "d9085uknnhn"
      },
      "source": [
        "### Example: Human Review Checklist\n",
        "\n",
        "```python\n",
        "HUMAN_REVIEW_CHECKLIST = {\n",
        "    \"factual_accuracy\": {\n",
        "        \"question\": \"Are all factual claims accurate?\",\n",
        "        \"type\": \"yes_no_unsure\",\n",
        "    },\n",
        "    \"source_verification\": {\n",
        "        \"question\": \"Did you spot-check at least one source URL?\",\n",
        "        \"type\": \"yes_no\",\n",
        "    },\n",
        "    \"user_helpful\": {\n",
        "        \"question\": \"Would this be helpful to someone researching this topic?\",\n",
        "        \"type\": \"scale_1_5\",\n",
        "    },\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qbke7gzm6c",
      "metadata": {
        "id": "qbke7gzm6c"
      },
      "source": [
        "### Key principles for human review\n",
        "\n",
        "1. **Structure the review** - Don't ask \"is this good?\", ask specific questions\n",
        "2. **Use checklists** - Binary yes/no questions are faster and more consistent\n",
        "3. **Provide context** - Show reviewers what they need to evaluate\n",
        "4. **Collect rationale** - Ask reviewers to explain their judgments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "synthesis-header",
      "metadata": {
        "id": "synthesis-header"
      },
      "source": [
        "---\n",
        "## Putting It Together\n",
        "\n",
        "In practice, you'll often combine multiple evaluation types:\n",
        "\n",
        "```\n",
        "Agent Output\n",
        "    â”‚\n",
        "    â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ Objective Checksâ”‚ â”€â”€â–º Fast, cheap, catches obvious issues\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "         â”‚\n",
        "         â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚   LLM Judge     â”‚ â”€â”€â–º Scalable quality assessment  \n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "         â”‚\n",
        "         â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  Human Review   â”‚ â”€â”€â–º High-stakes verification (sample)\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h5c8gfeqqeu",
      "metadata": {
        "id": "h5c8gfeqqeu"
      },
      "source": [
        "### The Key Insight\n",
        "\n",
        "**Layer your evaluations by cost and coverage:**\n",
        "\n",
        "| Method | Cost | Coverage | Best For |\n",
        "|--------|------|----------|----------|\n",
        "| Objective checks | Low | 100% | Catching obvious failures |\n",
        "| LLM-as-judge | Medium | 100% | Quality assessment at scale |\n",
        "| Human review | High | Sample | Validation, edge cases |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "takeaways-header",
      "metadata": {
        "id": "takeaways-header"
      },
      "source": [
        "---\n",
        "## Key Takeaways\n",
        "\n",
        "1. **Component-level evals** let you test individual pieces of an AI system\n",
        "\n",
        "2. **Objective evaluations** (ground truth) are fast, cheap, reproducible\n",
        "\n",
        "3. **LLM-as-judge** scales subjective evaluation but requires rubric design\n",
        "\n",
        "4. **Human review** is essential for high-stakes and domain expertise\n",
        "\n",
        "5. **Combine methods** for robust evaluation pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26288faf",
      "metadata": {
        "id": "26288faf"
      },
      "source": [
        "---\n",
        "## Activity: Design Evals for a Comms Agent\n",
        "\n",
        "Let's apply what we've learned to a real-world Nesta project."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "974ce02e",
      "metadata": {
        "id": "974ce02e"
      },
      "source": [
        "### The Problem\n",
        "\n",
        "We're building an agentic AI solution to [assist heat pump installers with their admin workload](https://www.nesta.org.uk/project/showing-the-practical-value-of-agentic-ai-for-driving-impact/).\n",
        "\n",
        "The **Communications Agent** helps interpret and reply to incoming emails and documents about grid connection applications."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca24086",
      "metadata": {
        "id": "eca24086"
      },
      "source": [
        "### Agent Capabilities\n",
        "\n",
        "1. **Triage emails** â€” Categorise incoming messages by action required\n",
        "2. **Extract key information from PDFs** â€” Pull out relevant data from attached documents\n",
        "3. **Summarise and present context** â€” Give human reviewers the information they need\n",
        "\n",
        "**Your task**: In small groups, brainstorm evaluation strategies for each capability."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hi1h3b401f",
      "metadata": {
        "id": "hi1h3b401f"
      },
      "source": [
        "### Think About: The Evaluation Quadrant\n",
        "\n",
        "For each capability, consider:\n",
        "- **Do we have ground truth?** Can we know the \"correct\" answer in advance?\n",
        "- **Can code check it?** Or do we need LLM-as-judge / human review?\n",
        "\n",
        "| Capability | Ground Truth? | Eval Method? |\n",
        "|------------|---------------|--------------|\n",
        "| Email triage | ? | ? |\n",
        "| PDF extraction | ? | ? |\n",
        "| Summarise context | ? | ? |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15326cad",
      "metadata": {
        "id": "15326cad"
      },
      "source": [
        "### Capability 1: Email Triage\n",
        "\n",
        "The agent categorises emails into one of three actions:\n",
        "- **Ignore** â€” No action needed (spam, irrelevant, already handled)\n",
        "- **Notify** â€” Flag for human attention but no response needed\n",
        "- **Respond** â€” Needs a reply\n",
        "\n",
        "**Context**: These are emails from a Distribution Network Operator (DNO) to heat pump installers regarding grid connection applications."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c094ad0",
      "metadata": {
        "id": "7c094ad0"
      },
      "source": [
        "**Email A:**\n",
        "> From: connections@ukpowernetworks.co.uk  \n",
        "> Subject: Application HP-2024-78432 - Additional information required\n",
        ">\n",
        "> Dear Installer,\n",
        ">\n",
        "> We are processing your G99 application for the property at 14 Willow Lane, Cambridge, CB4 1AB.\n",
        ">\n",
        "> Before we can proceed, please provide:\n",
        "> - Single line diagram showing isolation points\n",
        "> - Confirmation of maximum export capacity (kW)\n",
        ">\n",
        "> Please respond within 10 working days or your application may be closed.\n",
        ">\n",
        "> Regards,  \n",
        "> UK Power Networks Connections Team\n",
        "\n",
        "---\n",
        "\n",
        "**Email B:**\n",
        "> From: no-reply@ukpowernetworks.co.uk  \n",
        "> Subject: Planned maintenance notification - Eastern region\n",
        ">\n",
        "> This is an automated message.\n",
        ">\n",
        "> Planned maintenance will take place in the Eastern region on 15th December 2024 between 02:00-05:00. Some online services may be unavailable during this period.\n",
        ">\n",
        "> No action is required.\n",
        ">\n",
        "> UK Power Networks\n",
        "\n",
        "---\n",
        "\n",
        "**Email C:**\n",
        "> From: connections@ukpowernetworks.co.uk  \n",
        "> Subject: Re: HP-2024-81205 - Application approved\n",
        ">\n",
        "> Dear Installer,\n",
        ">\n",
        "> Your G99 application for 27 Oak Street, Norwich, NR1 3PQ has been approved.\n",
        ">\n",
        "> Please find attached your connection offer and acceptance form. The offer is valid for 90 days.\n",
        ">\n",
        "> If you have any questions, please contact us quoting your reference number.\n",
        ">\n",
        "> Best regards,  \n",
        "> Connections Team\n",
        "\n",
        "---\n",
        "\n",
        "**Write your labels:**\n",
        "```\n",
        "Email A:  [ ] Ignore   [ ] Notify   [ ] Respond\n",
        "\n",
        "Email B:  [ ] Ignore   [ ] Notify   [ ] Respond\n",
        "\n",
        "Email C:  [ ] Ignore   [ ] Notify   [ ] Respond\n",
        "```\n",
        "\n",
        "**Discussion**: Did everyone agree? What context would change your answer?\n",
        "\n",
        "---\n",
        "\n",
        "**Design the eval:**\n",
        "- Does this have ground truth?\n",
        "- Can code check it, or do you need LLM-as-judge?\n",
        "- What test cases would you create?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc2b34e3",
      "metadata": {
        "id": "cc2b34e3"
      },
      "source": [
        "### Capability 2: PDF Information Extraction\n",
        "\n",
        "The agent reads attached documents and extracts key information: addresses, quote amounts, and flags any discrepancies.\n",
        "\n",
        "**Context**: Heat pump installers receive quotes from suppliers. The agent should extract structured data and catch errors.\n",
        "\n",
        "**Your task**: Review this quote and extract the required fields. Can you spot the discrepancy?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "655383e8",
      "metadata": {
        "id": "655383e8"
      },
      "source": [
        "<div style=\"font-family: Arial, sans-serif; max-width: 600px; border: 1px solid #ccc; padding: 24px; background: #fff; margin: 16px 0;\">\n",
        "\n",
        "<div style=\"display: flex; justify-content: space-between; align-items: start; margin-bottom: 20px;\">\n",
        "<div>\n",
        "<div style=\"font-size: 20px; font-weight: bold; color: #1e40af;\">HeatFlow Supplies Ltd</div>\n",
        "<div style=\"font-size: 12px; color: #666;\">Unit 7, Riverside Industrial Estate<br>Norwich, NR3 1QS<br>VAT: GB 123 4567 89</div>\n",
        "</div>\n",
        "<div style=\"text-align: right;\">\n",
        "<div style=\"font-size: 24px; font-weight: bold; color: #333;\">QUOTATION</div>\n",
        "<div style=\"font-size: 12px; color: #666;\">Quote #: HF-Q-2024-0892<br>Date: 22 Nov 2024<br>Valid until: 22 Dec 2024</div>\n",
        "</div>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #f8fafc; padding: 12px; margin-bottom: 20px; border-radius: 4px;\">\n",
        "<div style=\"font-size: 11px; color: #666; text-transform: uppercase;\">Quote For:</div>\n",
        "<div style=\"font-weight: 600;\">GreenHeat Installations Ltd</div>\n",
        "<div style=\"font-size: 13px;\">47 Churchill Road<br>Ipswich, Suffolk<br>IP4 2QT</div>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #f8fafc; padding: 12px; margin-bottom: 20px; border-radius: 4px;\">\n",
        "<div style=\"font-size: 11px; color: #666; text-transform: uppercase;\">Installation Address:</div>\n",
        "<div style=\"font-size: 13px;\">14 Willow Lane<br>Cambridge<br>CB4 1AB</div>\n",
        "</div>\n",
        "\n",
        "<table style=\"width: 100%; border-collapse: collapse; font-size: 13px; margin-bottom: 20px;\">\n",
        "<thead>\n",
        "<tr style=\"background: #1e40af; color: white;\">\n",
        "<th style=\"padding: 10px; text-align: left;\">Description</th>\n",
        "<th style=\"padding: 10px; text-align: center;\">Qty</th>\n",
        "<th style=\"padding: 10px; text-align: right;\">Unit Price</th>\n",
        "<th style=\"padding: 10px; text-align: right;\">Amount</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr style=\"border-bottom: 1px solid #e5e7eb;\">\n",
        "<td style=\"padding: 10px;\">Vaillant Arotherm Plus 7kW Heat Pump</td>\n",
        "<td style=\"padding: 10px; text-align: center;\">1</td>\n",
        "<td style=\"padding: 10px; text-align: right;\">Â£4,250.00</td>\n",
        "<td style=\"padding: 10px; text-align: right;\">Â£4,250.00</td>\n",
        "</tr>\n",
        "<tr style=\"border-bottom: 1px solid #e5e7eb;\">\n",
        "<td style=\"padding: 10px;\">Vaillant uniTOWER 190L Cylinder</td>\n",
        "<td style=\"padding: 10px; text-align: center;\">1</td>\n",
        "<td style=\"padding: 10px; text-align: right;\">Â£1,850.00</td>\n",
        "<td style=\"padding: 10px; text-align: right;\">Â£1,850.00</td>\n",
        "</tr>\n",
        "<tr style=\"border-bottom: 1px solid #e5e7eb;\">\n",
        "<td style=\"padding: 10px;\">Installation Kit & Refrigerant Lines (15m)</td>\n",
        "<td style=\"padding: 10px; text-align: center;\">1</td>\n",
        "<td style=\"padding: 10px; text-align: right;\">Â£420.00</td>\n",
        "<td style=\"padding: 10px; text-align: right;\">Â£420.00</td>\n",
        "</tr>\n",
        "<tr style=\"border-bottom: 1px solid #e5e7eb;\">\n",
        "<td style=\"padding: 10px;\">Delivery & Handling</td>\n",
        "<td style=\"padding: 10px; text-align: center;\">1</td>\n",
        "<td style=\"padding: 10px; text-align: right;\">Â£85.00</td>\n",
        "<td style=\"padding: 10px; text-align: right;\">Â£85.00</td>\n",
        "</tr>\n",
        "<tr style=\"border-bottom: 1px solid #e5e7eb;\">\n",
        "<td style=\"padding: 10px;\">Delivery & Handling</td>\n",
        "<td style=\"padding: 10px; text-align: center;\">1</td>\n",
        "<td style=\"padding: 10px; text-align: right;\">Â£85.00</td>\n",
        "<td style=\"padding: 10px; text-align: right;\">Â£85.00</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>\n",
        "\n",
        "<div style=\"display: flex; justify-content: flex-end;\">\n",
        "<table style=\"font-size: 13px; min-width: 200px;\">\n",
        "<tr>\n",
        "<td style=\"padding: 6px 12px;\">Subtotal:</td>\n",
        "<td style=\"padding: 6px 12px; text-align: right;\">Â£6,690.00</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td style=\"padding: 6px 12px;\">VAT (20%):</td>\n",
        "<td style=\"padding: 6px 12px; text-align: right;\">Â£1,338.00</td>\n",
        "</tr>\n",
        "<tr style=\"font-weight: bold; font-size: 15px; border-top: 2px solid #1e40af;\">\n",
        "<td style=\"padding: 10px 12px;\">Total:</td>\n",
        "<td style=\"padding: 10px 12px; text-align: right;\">Â£8,028.00</td>\n",
        "</tr>\n",
        "</table>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 24px; padding-top: 16px; border-top: 1px solid #e5e7eb; font-size: 11px; color: #666;\">\n",
        "<strong>Terms:</strong> Payment due within 30 days of invoice. Prices valid for 30 days from quote date.<br>\n",
        "<strong>Lead time:</strong> 5-7 working days from order confirmation.\n",
        "</div>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fc7c2f9",
      "metadata": {
        "id": "3fc7c2f9"
      },
      "source": [
        "**Extract the following:**\n",
        "```\n",
        "Installation address:  _______________________________________________\n",
        "\n",
        "Quote total (inc VAT): _______________________________________________\n",
        "\n",
        "Discrepancy found:     _______________________________________________\n",
        "```\n",
        "\n",
        "**Design the eval:**\n",
        "- Does this have ground truth?\n",
        "- Can code check it, or do you need LLM-as-judge?\n",
        "- How would you test discrepancy detection?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6854f379",
      "metadata": {
        "id": "6854f379"
      },
      "source": [
        "### Capability 3: Summarise and Present Context\n",
        "\n",
        "The agent creates summaries that give human reviewers the context they need to make decisions.\n",
        "\n",
        "**Context**: The installer received the DNO email (Email A) requesting additional information. The agent should summarise this for the installer to action.\n",
        "\n",
        "**Your task**: Review these 3 agent-generated summaries and rank them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb60439a",
      "metadata": {
        "id": "fb60439a"
      },
      "source": [
        "**Summary A:**\n",
        "> UK Power Networks sent an email about application HP-2024-78432.\n",
        "\n",
        "---\n",
        "\n",
        "**Summary B:**\n",
        "> **Action required**: DNO requesting additional documents for 14 Willow Lane, Cambridge (HP-2024-78432).\n",
        ">\n",
        "> They need:\n",
        "> - Single line diagram with isolation points\n",
        "> - Max export capacity confirmation\n",
        ">\n",
        "> **Deadline**: 10 working days or application may be closed.\n",
        "\n",
        "---\n",
        "\n",
        "**Summary C:**\n",
        "> You have received correspondence from UK Power Networks regarding your G99 grid connection application. The application reference number is HP-2024-78432 and it pertains to the property located at 14 Willow Lane, Cambridge, CB4 1AB. The Distribution Network Operator has indicated that they require additional documentation before they can continue processing your application. Specifically, they have requested that you provide a single line diagram that clearly shows the isolation points, as well as confirmation of the maximum export capacity measured in kilowatts (kW). It is important to note that you should respond to this request within a timeframe of 10 working days. If you do not respond within this period, there is a possibility that your application may be closed.\n",
        "\n",
        "---\n",
        "\n",
        "**Rank them (1 = best, 3 = worst):**\n",
        "```\n",
        "Summary A:  Rank ___   Why? ________________________________________\n",
        "\n",
        "Summary B:  Rank ___   Why? ________________________________________\n",
        "\n",
        "Summary C:  Rank ___   Why? ________________________________________\n",
        "```\n",
        "\n",
        "**Design the eval:**\n",
        "- Does this have ground truth?\n",
        "- Can code check it, or do you need LLM-as-judge?\n",
        "- What rubric criteria would you use?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04fe7c83",
      "metadata": {
        "id": "04fe7c83"
      },
      "source": [
        "### Group Discussion: Share Your Ideas\n",
        "\n",
        "After brainstorming, let's share:\n",
        "\n",
        "1. **Which capabilities are easiest to evaluate? Why?**\n",
        "\n",
        "2. **Which need human review? What expertise is required?**\n",
        "\n",
        "3. **What surprised you about designing these evals?**\n",
        "\n",
        "4. **What would you prioritise building first?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0naeomt2on",
      "metadata": {
        "id": "f0naeomt2on"
      },
      "source": [
        "---\n",
        "## Next Steps\n",
        "\n",
        "To build a proper evaluation suite:\n",
        "\n",
        "1. **Create an eval set**: 10-20 diverse test cases\n",
        "2. **Define ground truth**: What should pass/fail?\n",
        "3. **Run evals regularly**: Track metrics over time\n",
        "4. **Iterate**: Improve your agent based on results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31c21b41",
      "metadata": {
        "id": "31c21b41"
      },
      "source": [
        "---\n",
        "## Thank You!\n",
        "\n",
        "Learn more about the agentic AI residency:\n",
        "\n",
        "- **[Nesta welcomes AI agents resident](https://www.nesta.org.uk/project-updates/nesta-welcomes-ai-agents-resident/)**\n",
        "\n",
        "- **[Showing the practical value of agentic AI for driving impact](https://www.nesta.org.uk/project/showing-the-practical-value-of-agentic-ai-for-driving-impact/)**\n",
        "\n",
        "- **[The challenges of DNO applications for heat pump installers](https://www.nesta.org.uk/project-updates/the-challenges-of-distribution-network-operator-applications-for-heat-pump-installers/)**\n",
        "\n",
        "Questions? Let's discuss!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d124ba04",
      "metadata": {
        "id": "d124ba04"
      },
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "rise": {
      "autolaunch": false,
      "enable_chalkboard": true,
      "footer": "Evaluating AI Agents Workshop",
      "scroll": true,
      "start_slideshow_at": "selected",
      "theme": "simple",
      "transition": "slide"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}